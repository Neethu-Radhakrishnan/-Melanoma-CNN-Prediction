{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neethu-Radhakrishnan/Melanoma-CNN-Prediction/blob/main/Schifra_Neethu_Sakshi_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ],
      "metadata": {
        "id": "yDriIbfa5lwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Skin Cancer Data\n",
        "#### To do: Take necessary actions to read the data"
      ],
      "metadata": {
        "id": "lvR7ppk77v31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing all the important libraries"
      ],
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the relevant libraries\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "WC8xCQuELWms",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:42.245133Z",
          "iopub.execute_input": "2023-01-29T15:24:42.245542Z",
          "iopub.status.idle": "2023-01-29T15:24:42.251886Z",
          "shell.execute_reply.started": "2023-01-29T15:24:42.245510Z",
          "shell.execute_reply": "2023-01-29T15:24:42.250699Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## If you are using the data by mounting the google drive, use the following :\n",
        "# Mounting the drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "##Ref:https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"
      ],
      "metadata": {
        "id": "TYpVPmT5z7AP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e54c04-1c39-417d-dbac-9a41ec74abc9",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.191544Z",
          "iopub.status.idle": "2023-01-29T15:24:33.192480Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.192183Z",
          "shell.execute_reply": "2023-01-29T15:24:33.192227Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ],
      "metadata": {
        "id": "RpUsRQwOOL72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the dataset\n",
        "!unzip \"/content/gdrive/MyDrive/CNN_assignment.zip\" > /dev/null"
      ],
      "metadata": {
        "id": "Y8fj5JDBOyGB",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.194205Z",
          "iopub.status.idle": "2023-01-29T15:24:33.195110Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.194836Z",
          "shell.execute_reply": "2023-01-29T15:24:33.194863Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f77c8c4-3404-44e8-a7cf-db65cca78bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Skin cancer ISIC The International Skin Imaging Collaboration/Test/actinic keratosis/ISIC_0010512.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the path for train and test images\n",
        "## Todo: Update the paths of the train and test dataset\n",
        "data_dir_train = pathlib.Path('/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train')\n",
        "data_dir_test = pathlib.Path('/content/Skin cancer ISIC The International Skin Imaging Collaboration/Test')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.199403Z",
          "iopub.status.idle": "2023-01-29T15:24:33.200336Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.200049Z",
          "shell.execute_reply": "2023-01-29T15:24:33.200075Z"
        },
        "trusted": true,
        "id": "VWAFkoPm1yw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting number of images in train and test\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "metadata": {
        "id": "DqksN1w5Fu-N",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:55.348703Z",
          "iopub.execute_input": "2023-01-29T15:24:55.349113Z",
          "iopub.status.idle": "2023-01-29T15:24:55.371179Z",
          "shell.execute_reply.started": "2023-01-29T15:24:55.349070Z",
          "shell.execute_reply": "2023-01-29T15:24:55.369572Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load using keras.preprocessing\n",
        "\n",
        "Let's load these images off disk using the helpful image_dataset_from_directory utility."
      ],
      "metadata": {
        "id": "O8HkfW3jPJun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a dataset\n",
        "\n",
        "Define some parameters for the loader:"
      ],
      "metadata": {
        "id": "cDBKZG3jPcMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the parameters\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "VLfcXcZ9LjGv",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:01.555242Z",
          "iopub.execute_input": "2023-01-29T15:25:01.556380Z",
          "iopub.status.idle": "2023-01-29T15:25:01.561476Z",
          "shell.execute_reply.started": "2023-01-29T15:25:01.556340Z",
          "shell.execute_reply": "2023-01-29T15:25:01.560351Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ],
      "metadata": {
        "id": "Y5f5y43GPog1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your train dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed= 123,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    image_size =(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "G1BWmDzr7w-5",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:06.222726Z",
          "iopub.execute_input": "2023-01-29T15:25:06.223126Z",
          "iopub.status.idle": "2023-01-29T15:25:06.359793Z",
          "shell.execute_reply.started": "2023-01-29T15:25:06.223093Z",
          "shell.execute_reply": "2023-01-29T15:25:06.358008Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your validation dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed= 123,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    image_size =(img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "LYch6-SR-i2g",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:11.003500Z",
          "iopub.execute_input": "2023-01-29T15:25:11.003866Z",
          "iopub.status.idle": "2023-01-29T15:25:11.130891Z",
          "shell.execute_reply.started": "2023-01-29T15:25:11.003834Z",
          "shell.execute_reply": "2023-01-29T15:25:11.129872Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List out all the classes of skin cancer and store them in a list. \n",
        "# You can find the class names in the class_names attribute on these datasets. \n",
        "# These correspond to the directory names in alphabetical order.\n",
        "#Listing the names of the classes\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "Bk0RV7G7-nad",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:16.493129Z",
          "iopub.execute_input": "2023-01-29T15:25:16.493879Z",
          "iopub.status.idle": "2023-01-29T15:25:16.499860Z",
          "shell.execute_reply.started": "2023-01-29T15:25:16.493839Z",
          "shell.execute_reply": "2023-01-29T15:25:16.498669Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the data\n",
        "#### Todo, create a code to visualize one instance of all the nine classes present in the dataset"
      ],
      "metadata": {
        "id": "jbsm5oYiQH_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualising an image for each class\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### your code goes here, you can use training or validation data to visualize\n",
        "plt.figure(figsize=(15,15))\n",
        "for I in range(9):\n",
        "  plt.subplot(3, 3, I+1)\n",
        "  img = plt.imread(str(list(data_dir_train.glob(class_names[I]+'/*.jpg'))[1]))\n",
        "  plt.title(class_names[I])\n",
        "  plt.imshow(img)"
      ],
      "metadata": {
        "id": "tKILZ48I-q1k",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:21.164239Z",
          "iopub.execute_input": "2023-01-29T15:25:21.164609Z",
          "iopub.status.idle": "2023-01-29T15:25:21.360628Z",
          "shell.execute_reply.started": "2023-01-29T15:25:21.164579Z",
          "shell.execute_reply": "2023-01-29T15:25:21.358562Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ],
      "metadata": {
        "id": "8cAZPYaeQjQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "jzVXBHiyQ7_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "7wZlKRBEGNtU",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:28.477641Z",
          "iopub.execute_input": "2023-01-29T15:25:28.478010Z",
          "iopub.status.idle": "2023-01-29T15:25:28.486532Z",
          "shell.execute_reply.started": "2023-01-29T15:25:28.477978Z",
          "shell.execute_reply": "2023-01-29T15:25:28.485374Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the model\n",
        "#### Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
      ],
      "metadata": {
        "id": "1JEAF6-sRyz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a convolution model\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "num_classes = 9\n",
        "model = Sequential([\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "k2GY4ndis4ys",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:52.021608Z",
          "iopub.execute_input": "2023-01-29T15:25:52.021970Z",
          "iopub.status.idle": "2023-01-29T15:25:52.125057Z",
          "shell.execute_reply.started": "2023-01-29T15:25:52.021938Z",
          "shell.execute_reply": "2023-01-29T15:25:52.124129Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model\n",
        "Choose an appropirate optimiser and loss function for model training "
      ],
      "metadata": {
        "id": "SDKzJmHwSCtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Todo, choose an appropirate optimiser and loss function\n",
        "#Setting the optimiser and loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XB8wKtiPGe1j",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:25:59.531823Z",
          "iopub.execute_input": "2023-01-29T15:25:59.532175Z",
          "iopub.status.idle": "2023-01-29T15:25:59.543295Z",
          "shell.execute_reply.started": "2023-01-29T15:25:59.532144Z",
          "shell.execute_reply": "2023-01-29T15:25:59.542262Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the summary of all layers\n",
        "#Finding the summary of all the layers in the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_ZGWN4MZGhtJ",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:26:02.802754Z",
          "iopub.execute_input": "2023-01-29T15:26:02.803145Z",
          "iopub.status.idle": "2023-01-29T15:26:02.810354Z",
          "shell.execute_reply.started": "2023-01-29T15:26:02.803114Z",
          "shell.execute_reply": "2023-01-29T15:26:02.809104Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "ljD_83rwSl5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model with 30 epoch\n",
        "epochs = 30\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Kkfw2rJXGlYC",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:26:08.736696Z",
          "iopub.execute_input": "2023-01-29T15:26:08.737088Z",
          "iopub.status.idle": "2023-01-29T15:28:11.903786Z",
          "shell.execute_reply.started": "2023-01-29T15:26:08.737045Z",
          "shell.execute_reply": "2023-01-29T15:28:11.902866Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing training results"
      ],
      "metadata": {
        "id": "w3679V8OShSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualising the results from training the model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1xkgk5nGubz",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:28:56.827265Z",
          "iopub.execute_input": "2023-01-29T15:28:56.828012Z",
          "iopub.status.idle": "2023-01-29T15:28:57.150692Z",
          "shell.execute_reply.started": "2023-01-29T15:28:56.827976Z",
          "shell.execute_reply": "2023-01-29T15:28:57.149724Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit"
      ],
      "metadata": {
        "id": "JvPphJYuSZhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write your findings here"
      ],
      "metadata": {
        "id": "3vRTPbJEn-pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The maximum accuracy is around 87%. However the validation accuracy is about 56%. The gap between the blue line and orange line shows that there is strong evidence of Overfitting.**"
      ],
      "metadata": {
        "id": "ExSZnRZF6PGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo, after you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n",
        "# Your code goes here\n",
        "#Implementing the data_augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(mode= \"horizontal_and_vertical\",input_shape=(img_height,img_width,3)), #Randomly flipping the images\n",
        "  layers.RandomRotation(0.2,fill_mode='reflect'),      #Randomly Rotating the images\n",
        "  layers.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3), fill_mode='reflect')  #Ramdomly zooming the images\n",
        "])"
      ],
      "metadata": {
        "id": "22hljAl6GykA",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:29:07.022915Z",
          "iopub.execute_input": "2023-01-29T15:29:07.023323Z",
          "iopub.status.idle": "2023-01-29T15:29:07.177181Z",
          "shell.execute_reply.started": "2023-01-29T15:29:07.023289Z",
          "shell.execute_reply": "2023-01-29T15:29:07.176236Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo, visualize how your augmentation strategy works for one instance of training image.\n",
        "# Your code goes here\n",
        "# Displaying the images after performing Data_augmentation\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for I in range(9):\n",
        "        ax = plt.subplot(3, 3, I + 1)\n",
        "        plt.imshow(data_augmentation(images)[I].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[I]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "XEjPWh8GG0C7",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:29:09.397193Z",
          "iopub.execute_input": "2023-01-29T15:29:09.397623Z",
          "iopub.status.idle": "2023-01-29T15:29:10.572176Z",
          "shell.execute_reply.started": "2023-01-29T15:29:09.397588Z",
          "shell.execute_reply": "2023-01-29T15:29:10.570785Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Todo:\n",
        "### Create the model, compile and train the model\n"
      ],
      "metadata": {
        "id": "XhKDHlUdTuSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing BatchNormalisation for future use\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-29T15:29:18.493372Z",
          "iopub.execute_input": "2023-01-29T15:29:18.493745Z",
          "iopub.status.idle": "2023-01-29T15:29:18.498904Z",
          "shell.execute_reply.started": "2023-01-29T15:29:18.493712Z",
          "shell.execute_reply": "2023-01-29T15:29:18.497255Z"
        },
        "trusted": true,
        "id": "kKt1-PsX1yxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## You can use Dropout layer if there is an evidence of overfitting in your findings\n",
        "\n",
        "## Your code goes here\n",
        "#Running the training model with data augmentation with dropout layer\n",
        "\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "num_classes = 9\n",
        "model = Sequential([data_augmentation,\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "#Dropout layer with 30% Fraction of the input units to drop.\n",
        "model.add(layers.Dropout(0.30))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))\n"
      ],
      "metadata": {
        "id": "W3V4l-O9G3dM",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:36:26.569052Z",
          "iopub.execute_input": "2023-01-29T15:36:26.570023Z",
          "iopub.status.idle": "2023-01-29T15:36:26.818272Z",
          "shell.execute_reply.started": "2023-01-29T15:36:26.569983Z",
          "shell.execute_reply": "2023-01-29T15:36:26.817213Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "FfUWFp96UIAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code goes here\n",
        "#Selecting the optimizer and loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_-7yTm8IG8zR",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:36:34.088491Z",
          "iopub.execute_input": "2023-01-29T15:36:34.088861Z",
          "iopub.status.idle": "2023-01-29T15:36:34.101545Z",
          "shell.execute_reply.started": "2023-01-29T15:36:34.088829Z",
          "shell.execute_reply": "2023-01-29T15:36:34.100333Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "kC-D_RWOURp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code goes here, note: train your model for 20 epochs\n",
        "#Now running the model for 20 epochs\n",
        "epochs=20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "UcPfkUASHBf9",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:36:42.563671Z",
          "iopub.execute_input": "2023-01-29T15:36:42.564047Z",
          "iopub.status.idle": "2023-01-29T15:38:02.924844Z",
          "shell.execute_reply.started": "2023-01-29T15:36:42.564015Z",
          "shell.execute_reply": "2023-01-29T15:38:02.923559Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the results"
      ],
      "metadata": {
        "id": "IhNOKtSyUYzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualising the results of the model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vjN_F4QxHIsh",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:38:15.133264Z",
          "iopub.execute_input": "2023-01-29T15:38:15.134127Z",
          "iopub.status.idle": "2023-01-29T15:38:15.486145Z",
          "shell.execute_reply.started": "2023-01-29T15:38:15.134087Z",
          "shell.execute_reply": "2023-01-29T15:38:15.485148Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?"
      ],
      "metadata": {
        "id": "0-AUR_b7UcaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Overfitting problem has been eradicated.The distance between the blue line and Orange line is much less. The model accuracy is around 53% and the Validation accuracy is around 52%. The model accuracy and validation accuracy are very close to each other but are much less now as compared to before data_augmentation.**"
      ],
      "metadata": {
        "id": "Ewr7Qlus9ANR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Find the distribution of classes in the training dataset.\n",
        "#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
      ],
      "metadata": {
        "id": "7TdDi4u-VTkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code goes here.\n",
        "#Visualising the number of images per class through a barchart.\n",
        "import matplotlib.pyplot as plt\n",
        "data = dict()\n",
        "\n",
        "for i in class_names:\n",
        "  data[i] = []\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds:\n",
        "  for i in range(9):\n",
        "    data[class_names[labels[i]]].append(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "for i in data:\n",
        "  data[i] = len(data[i]) \n",
        "\n",
        "f = plt.figure()\n",
        "f.set_figwidth(20)\n",
        "f.set_figheight(20)\n",
        "\n",
        "plt.bar(range(len(data)), list(data.values()), align='center')\n",
        "plt.xticks(range(len(data)), list(data.keys()))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HAhwYgtTQRzq",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:39:15.592690Z",
          "iopub.execute_input": "2023-01-29T15:39:15.593922Z",
          "iopub.status.idle": "2023-01-29T15:39:16.388278Z",
          "shell.execute_reply.started": "2023-01-29T15:39:15.593879Z",
          "shell.execute_reply": "2023-01-29T15:39:16.387231Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code goes here.\n",
        "#Finding out the number of images in each class\n",
        "class_balance_check={}\n",
        "for i in class_names:\n",
        "  class_balance_check[i]= len(list(data_dir_train.glob(i+'/*.jpg')))\n",
        "class_balance_check"
      ],
      "metadata": {
        "id": "0h4w7V60WBCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pigmented benign keratosis is the most common one (462), followed by  melanoma (438),basal cell carcinoma (376), nevus (357), squamous cell carcinoma (181), vascular lesion (139), actinic keratosis (114), dermatofibroma ( 95), seborrheic keratosis(77).**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D8s-7i7P-eTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Write your findings here: \n",
        "#### - Which class has the least number of samples?\n",
        "#### - Which classes dominate the data in terms proportionate number of samples?\n"
      ],
      "metadata": {
        "id": "4csQL1dvO0b2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Seborrheic Keratosis (77) has the least number of samples.**\n",
        "*   **The classes which dominate the data the most are pigmented benign keratosis (462), melanoma (438), basal cell carcinoma (376) and nevus (357) and they contribute to nearly 72% of the data**. \n",
        "\n"
      ],
      "metadata": {
        "id": "fHUfmGhj_83j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Rectify the class imbalance\n",
        "#### **Context:** You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
      ],
      "metadata": {
        "id": "Hb-stKyHPf8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing Augmantor\n",
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "ItAg4rU-SzJh",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:44:38.114561Z",
          "iopub.execute_input": "2023-01-29T15:44:38.114980Z",
          "iopub.status.idle": "2023-01-29T15:47:07.719693Z",
          "shell.execute_reply.started": "2023-01-29T15:44:38.114944Z",
          "shell.execute_reply": "2023-01-29T15:47:07.718447Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Augmentor and running it all the classes equal with a sample image of 500 per category, thus balancing the data\n",
        "path_to_training_dataset=\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset +'/'+ i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n",
        "    p.sample(500)"
      ],
      "metadata": {
        "id": "YT78WQaAWYIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipelineâ€™s` `sample()` method.\n"
      ],
      "metadata": {
        "id": "BZKzTe3zWL4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ],
      "metadata": {
        "id": "CcBIFZGbWuFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the total number of images in the training dataset \n",
        "#It is now 4500\n",
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "metadata": {
        "id": "zDWBgV6RXMhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ],
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing glob from glob\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "RqZ76cZ7Yq_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_list = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "path_list"
      ],
      "metadata": {
        "id": "rZ4O1a9nPuUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "lesion_list_new"
      ],
      "metadata": {
        "id": "KQjzIrVhY7qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
      ],
      "metadata": {
        "id": "SDTH0iUpZAs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now checking our new Df2 which includes the augmented data\n",
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "df2"
      ],
      "metadata": {
        "id": "wTLoRonQZEr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the classes are the same (500). Hence the data is now balanced\n",
        "df2['Label'].value_counts()"
      ],
      "metadata": {
        "id": "E9QYGjcXZJ2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ],
      "metadata": {
        "id": "9NirFBvGPmgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo**: Train the model on the data created using Augmentor"
      ],
      "metadata": {
        "id": "9EnspeMbRWNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the parameters\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "hFcj1XgndRWz",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.277247Z",
          "iopub.status.idle": "2023-01-29T15:24:33.278038Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.277776Z",
          "shell.execute_reply": "2023-01-29T15:24:33.277800Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Create a training dataset"
      ],
      "metadata": {
        "id": "0haOU11Ey8ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Recreating our training dataset\n",
        "data_dir_train=\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training', ## Todo choose the correct parameter value, so that only training data is refered to\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "uFP54lSkVHOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Create a validation dataset"
      ],
      "metadata": {
        "id": "mwNJVDuBP5kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating our validation dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation', ## Todo choose the correct parameter value, so that only training data is refered to\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "H4ZY11judRWz",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.279502Z",
          "iopub.status.idle": "2023-01-29T15:24:33.280311Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.280029Z",
          "shell.execute_reply": "2023-01-29T15:24:33.280056Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Create your model (make sure to include normalization)"
      ],
      "metadata": {
        "id": "JaoWeOEpVjqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same Model\n",
        "num_classes = 9\n",
        "model = Sequential([layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "])\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "#Dropout layer with 30% Fraction of the input units to drop.\n",
        "model.add(layers.Dropout(0.30))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))\n"
      ],
      "metadata": {
        "id": "gc4a8JuVNQtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:** Compile your model (Choose optimizer and loss function appropriately)"
      ],
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your code goes here\n",
        "#Selcting our optimizer and Loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H47GWmLbdRW1",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.286298Z",
          "iopub.status.idle": "2023-01-29T15:24:33.287083Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.286825Z",
          "shell.execute_reply": "2023-01-29T15:24:33.286851Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:**  Train your model"
      ],
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Running our model for 30 epoches\n",
        "epochs = 30\n",
        "## Your code goes here, use 30 epochs.\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "fcV6OdI4dRW1",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.288661Z",
          "iopub.status.idle": "2023-01-29T15:24:33.289446Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.289167Z",
          "shell.execute_reply": "2023-01-29T15:24:33.289218Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:**  Visualize the model results"
      ],
      "metadata": {
        "id": "iuvfCTsBWLMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the results of the model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lCTXwfkTdRW1",
        "execution": {
          "iopub.status.busy": "2023-01-29T15:24:33.290971Z",
          "iopub.status.idle": "2023-01-29T15:24:33.291770Z",
          "shell.execute_reply.started": "2023-01-29T15:24:33.291522Z",
          "shell.execute_reply": "2023-01-29T15:24:33.291546Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Todo:**  Analyze your results here. Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
        "\n"
      ],
      "metadata": {
        "id": "Way4lakC4_p0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   ***The batch normalization was used earlier but it worsen the performance of the model such that the Training accuracy and the validation accuracy were far apart. It showed that the model unfitted with batch normalisation. Hence it was removed and the performance of the model improved.***\n",
        "\n",
        "*   ***The highest training accuracy the model showed was 71% which was a big improvement. The highest Validation accuracy was about 60% . This is a massive improvement in the model in terms of accuracy. There is still a slight case of overfitting but the blue line and orange line are mostly close together which is a good indication of a decent model.***\n",
        "\n",
        "*  ***Thus, it can be said that Balancing the data improved the performance of the model.***\n",
        "\n",
        "*   ***Conclussion: For better performance the sample size of the data should be increased.***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GW8cnlvpEndL"
      }
    }
  ]
}